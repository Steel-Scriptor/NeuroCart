{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fwbY2swhMCy",
        "outputId": "47168670-af9f-41a4-cb63-43b196e0a39a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.7/767.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qq dotenv\n",
        "!pip install -qU langchain langchain-openai openai\n",
        "!pip install -qU langchain-community\n",
        "!pip install -qq pymupdf\n",
        "!pip install -qq tiktoken\n",
        "!pip install -qq faiss-cpu\n",
        "!pip install -qq langchain-huggingface\n",
        "!pip install -qq rank_bm25\n",
        "!pip install -qq fpdf\n",
        "!pip install -q urlextract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq transformers\n",
        "!pip install -qq python-dotenv\n",
        "!pip install -qq transformers\n",
        "!pip install -qq huggingface_hub\n",
        "!pip install -qq accelerate\n",
        "!pip install -qq langchain sentencepiece langchain_community\n",
        "!pip install -qU bitsandbytes\n",
        "!pip -qq install -U bs4 trafilatura\n",
        "!pip install -qU langchain-huggingface\n",
        "!pip install -qq requests_html lxml_html_clean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOtr3RP5m3xV",
        "outputId": "6ebb45b6-6c2b-4fb9-95ee-89f3b93e2e92"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.9/837.9 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dataproc-spark-connect 0.8.3 requires websockets>=14.0, but you have websockets 10.4 which is incompatible.\n",
            "yfinance 0.2.65 requires websockets>=13.0, but you have websockets 10.4 which is incompatible.\n",
            "google-genai 1.27.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 10.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq langchain_google_genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq_3d2DPno-B",
        "outputId": "89ef5d91-af41-4f7a-f1d5-c7b2ab66440c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/47.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.4 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai\n",
        "!pip install -qq --upgrade langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzi1yjL96HRG",
        "outputId": "0863a14c-7b79-46b4-88af-229b9c273d1a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.3 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-genai 2.1.8 requires google-ai-generativelanguage<0.7.0,>=0.6.18, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To convert md files to PDFs, a particlur suitable font download is needed\n",
        "\n",
        "!apt-get install -y fonts-dejavu-core\n",
        "!ls -l /usr/share/fonts/truetype/dejavu/DejaVuSans.ttf #to check if the font is correctly loaded or not?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9_JSlt9kUW0",
        "outputId": "f115b608-c17d-4b49-fc89-841e9dcf62fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 1,041 kB of archives.\n",
            "After this operation, 3,025 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Fetched 1,041 kB in 1s (1,246 kB/s)\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "(Reading database ... 126284 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "-rw-r--r-- 1 root root 757076 Jul 30  2016 /usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "nltk.download(\"averaged_perceptron_tagger_eng\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoIxFZCigZ_j",
        "outputId": "d6173744-36f2-4ed2-e7c5-cf24dfb017be"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import openai\n",
        "import json\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "from fpdf import FPDF\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "from bs4 import BeautifulSoup\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "xd0WYKx1hycO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib #for importing the models\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from google.colab import files\n",
        "import csv, glob\n",
        "import warnings, datetime, textwrap, sys\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "23bEBmuxgfjF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re, fitz, pathlib\n",
        "from urlextract import URLExtract\n",
        "from langchain.schema import Document\n",
        "import shutil\n",
        "import torch\n",
        "from IPython.display import Markdown\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline"
      ],
      "metadata": {
        "id": "2p1EcRbxh1DC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the langchain frameworks\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter #for creating the chunks\n",
        "from langchain.embeddings import HuggingFaceEmbeddings #for creating the embeddings\n",
        "from langchain_community.vectorstores import FAISS #for vector store\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "import faiss #vector store\n",
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever #building the retriever\n",
        "from langchain.prompts import ChatPromptTemplate #converting the prompt string to feedable chat templates\n",
        "from langchain.schema import Document\n",
        "from langchain.schema.output_parser import StrOutputParser #parsing purpose\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.agents import create_tool_calling_agent, AgentExecutor"
      ],
      "metadata": {
        "id": "VY4Is0Vph2Iq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "import tiktoken as tkn #for counting the tokens"
      ],
      "metadata": {
        "id": "RQL7CDkBIiGX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer"
      ],
      "metadata": {
        "id": "zRDfw4YsPyn1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O56wyVErXVpS",
        "outputId": "29e75c4a-3853-4397-c364-ec65a3816340"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload the Gemini API Key\n"
      ],
      "metadata": {
        "id": "lYFa9G8AAMmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv('.env')\n",
        "import os\n",
        "api_key = os.getenv('GOOGLE_API_KEY')\n",
        "\n",
        "# Test output\n",
        "if not api_key:\n",
        "  print(\"No API key was found\")\n",
        "elif not api_key.startswith(\"AIza\") or len(api_key) < 30:\n",
        "  print(\"The API key does not appear to be valid\")\n",
        "else:\n",
        "  print(\"Google API key imported successfully.\")\n",
        "  print(f\"Your key starts with: {api_key[:5]}...\")"
      ],
      "metadata": {
        "id": "6pKNLvCzkRXp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "6ed063e4-39b9-41e2-8812-50310ff0c4cc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1b9118e5-8560-44c2-a737-d4c5d1a02cde\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1b9118e5-8560-44c2-a737-d4c5d1a02cde\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving .env to .env\n",
            "Google API key imported successfully.\n",
            "Your key starts with: AIzaS...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uploading the xgboost_classifier model, tf-idf vectorisation model, and standard scaler based, numeric_scaler model (all are .joblib files)"
      ],
      "metadata": {
        "id": "48hp3STJGx7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"upload the tf_idf_vectoriser.joblib file\")\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "e-ZT8hlDHbow",
        "outputId": "1c6f755e-040a-400b-8b46-34590665fb31"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "upload the tf_idf_vectoriser.joblib file\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0faf638d-b2b7-4a70-b3ef-48cd1f91a9c2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0faf638d-b2b7-4a70-b3ef-48cd1f91a9c2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving tfidf_vectorizer.joblib to tfidf_vectorizer.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"upload the numeric_scaler.joblib file\")\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "CAi6ICWvHdrC",
        "outputId": "9afea020-a9ef-4651-d7d4-0501493d8b6c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "upload the numeric_scaler.joblib file\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-319348b3-2d1a-457a-8178-7c3d9622bd9a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-319348b3-2d1a-457a-8178-7c3d9622bd9a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving numeric_scaler.joblib to numeric_scaler.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "print(\"upload the model xgboost_classifier.joblib file\")\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "yPujm9RyfooH",
        "outputId": "aa0f5646-28fd-41c5-830f-20ba951388d6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "upload the model xgboost_classifier.joblib file\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-414295f5-0b31-4758-b2ac-3bb2090f231a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-414295f5-0b31-4758-b2ac-3bb2090f231a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving xgboost_classifier.joblib to xgboost_classifier.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload the scraping-dog API Key"
      ],
      "metadata": {
        "id": "8j4pR-If4Dw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Please upload the scraping-dog API key, .env file now.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "env_file = next(iter(uploaded))\n",
        "\n",
        "load_dotenv(dotenv_path=env_file)\n",
        "\n",
        "api_key = os.getenv('SCRAPINGDOG_API_KEY')\n",
        "\n",
        "if not api_key:\n",
        "  print(\"\\nScraping Dog API key was not found.\")\n",
        "  print(\"Check that your .env file contains: SCRAPINGDOG_API_KEY='...'\")\n",
        "else:\n",
        "  print(f\"\\nScraping Dog API key imported successfully!\")\n",
        "  print(f\"Your key starts with: {api_key[:5]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "7kayxI75yWLK",
        "outputId": "bd085012-877d-452a-b1de-5fd0ebb5d1d7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload the scraping-dog API key, .env file now.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-96a71272-06cb-4088-9627-dca5ced48b6a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-96a71272-06cb-4088-9627-dca5ced48b6a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving .env to .env (1)\n",
            "\n",
            "Scraping Dog API key imported successfully!\n",
            "Your key starts with: 686e4...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = joblib.load(\"tfidf_vectorizer.joblib\")\n",
        "scaler     = joblib.load(\"numeric_scaler.joblib\")\n",
        "model      = joblib.load(\"xgboost_classifier.joblib\")\n",
        "\n",
        "print(\"Loaded vectorizer, scaler, and xg_boost_classifier_trained_model.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KICBtZqHfoZ",
        "outputId": "b163c0cb-8ed8-4f50-a4b1-c488d183659a"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded vectorizer, scaler, and xg_boost_classifier_trained_model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"  Type 1 - To get product details, user reviews, and specifications etc.\")\n",
        "print(\"  Type 2 - To compare two different products based on user reviews and specififcations\")\n",
        "print(\"  Type 3 or more - To use the rank system to rank 3 or more products from the same category based on user reviews\\n\")\n",
        "num_links = int(input(\"How many product links would you like to upload?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUGI7QPp33p_",
        "outputId": "64e73705-8297-47dc-fe3d-d3ed1d4d212d"
      },
      "execution_count": 190,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Type 1 - To get product details, user reviews, and specifications etc.\n",
            "  Type 2 - To compare two different products based on user reviews and specififcations\n",
            "  Type 3 or more - To use the rank system to rank 3 or more products from the same category based on user reviews\n",
            "\n",
            "How many product links would you like to upload?3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# collecting the specified number of links\n",
        "product_links = []\n",
        "for i in range(num_links):\n",
        "    link = input(f\"Enter URL for product {i+1}: \").strip()\n",
        "    product_links.append(link)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgzzZzJY335C",
        "outputId": "234a733a-8f53-435f-d323-d6c2a8894af4"
      },
      "execution_count": 191,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter URL for product 1: https://www.walmart.com/ip/SAMSUNG-Galaxy-Watch-7-SM-L310N-44mm-Wi-Fi-Version-AI-ready-Bluetooth-Wellness-Tips-Heart-Rate-Tracking-Sleep-Monitor-Fitness-Tracker-Latin-Specs-Gre/11629002535?classType=VARIANT&athbdg=L1600&from=/search\n",
            "Enter URL for product 2: https://www.walmart.com/ip/Apple-Watch-Series-10-GPS-46mm-Jet-Black-Aluminum-Case-with-Black-Sport-Band-M-L/11381354322?classType=VARIANT&athbdg=L1102&from=/search\n",
            "Enter URL for product 3: https://www.walmart.com/ip/Garmin-vivoactive-5-Health-and-Fitness-GPS-Smartwatch-AMOLED-Display-Up-To-11-Days-Of-Battery-Ivory/5020233074?classType=VARIANT&from=/search\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the Json Folder\n",
        "folder_name = \"json_uploads\"\n",
        "os.makedirs(folder_name, exist_ok=True)\n",
        "print(f\"Folder created/verified: {folder_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx4X6xgn-d5V",
        "outputId": "5c5cb175-ca4f-4a3a-87d2-2d0bf0a27aa3"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder created/verified: json_uploads\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = os.getenv('SCRAPINGDOG_API_KEY')\n",
        "api_endpoint = \"https://api.scrapingdog.com/walmart/product\"\n",
        "\n",
        "for i, product_link in enumerate(product_links, start=1):\n",
        "\n",
        "    params = {\n",
        "        \"api_key\": api_key,\n",
        "        \"url\": product_link\n",
        "    }\n",
        "\n",
        "    print(f\"Scraping product {i}/{num_links}...\")\n",
        "    response = requests.get(api_endpoint, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "\n",
        "        product_id = product_link.split('/')[-1].split('?')[0]\n",
        "        filename = f\"{folder_name}/product_{i}_{product_id}.json\"\n",
        "\n",
        "        with open(filename, \"w\") as f:\n",
        "            json.dump(data, f, indent=4)\n",
        "\n",
        "        print(f\"Saved: {filename}\")\n",
        "    else:\n",
        "        print(f\"Failed to scrape product {i} — Status Code: {response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHH-DmdP33eg",
        "outputId": "78f45e82-b82b-4e5e-d3f4-a141e577db02"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping product 1/3...\n",
            "Saved: json_uploads/product_1_search.json\n",
            "Scraping product 2/3...\n",
            "Saved: json_uploads/product_2_search.json\n",
            "Scraping product 3/3...\n",
            "Saved: json_uploads/product_3_search.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CONVERTING THE JSON FILES TO MARKDOWN FILES"
      ],
      "metadata": {
        "id": "O4IBT4DPiobC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input/output folders\n",
        "input_folder = \"/content/json_uploads\"\n",
        "output_folder = \"/content/md_files\"\n",
        "os.makedirs(output_folder, exist_ok=True)"
      ],
      "metadata": {
        "id": "q-wuH8aKioeF"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_html(raw_html):\n",
        "    return BeautifulSoup(raw_html, \"html.parser\").get_text(separator=\"\\n\", strip=True)"
      ],
      "metadata": {
        "id": "3GIShNNFiog1"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".json\"):\n",
        "        with open(os.path.join(input_folder, filename), \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        product = data[\"product_results\"]\n",
        "        reviews_data = data.get(\"reviews_results\", {}).get(\"reviews\", {})\n",
        "        all_reviews = reviews_data.get(\"customer_reviews\", [])\n",
        "\n",
        "        title = product.get(\"title\", \"Unknown Title\")\n",
        "        short_desc = clean_html(product.get(\"short_description\", \"\"))\n",
        "        long_desc = clean_html(product.get(\"detailed_description_html\", \"\"))\n",
        "        specs = product.get(\"specifications\", [])\n",
        "\n",
        "        md = f\"# {title}\\n\\n\"\n",
        "        md += f\"**Product Page:** [{product.get('product_page_url')}]({product.get('product_page_url')})\\n\\n\"\n",
        "        md += f\"## Description\\n\\n{short_desc}\\n\\n{long_desc}\\n\\n\"\n",
        "\n",
        "        md += \"## Specifications\\n\"\n",
        "        for spec in specs:\n",
        "            name = spec.get(\"name\")\n",
        "            value = clean_html(spec.get(\"value\", \"\"))\n",
        "            md += f\"- **{name}**: {value}\\n\"\n",
        "\n",
        "        grouped_reviews = {i: [] for i in range(1, 6)}\n",
        "        for review in all_reviews:\n",
        "            grouped_reviews[review[\"rating\"]].append(review)\n",
        "\n",
        "        for star in range(1, 6):\n",
        "          md += f\"\\n## {star} Star Reviews\\n\\n\"\n",
        "          if grouped_reviews[star]:\n",
        "              for r in grouped_reviews[star]:\n",
        "                  title = (r.get(\"title\") or \"\").strip() or \"*No title*\"\n",
        "                  text = (r.get(\"text\") or \"\").strip()\n",
        "                  user = r.get(\"user_nickname\", \"anonymous\")\n",
        "                  date = r.get(\"review_submission_time\", \"\")\n",
        "                  md += f\"**{title}** by _{user}_ on {date}\\n\\n{text}\\n\\n---\\n\\n\"\n",
        "          else:\n",
        "              md += \"_No reviews in this category._\\n\\n\"\n",
        "\n",
        "\n",
        "        # Save\n",
        "        output_file = os.path.join(output_folder, Path(filename).stem + \".md\")\n",
        "        with open(output_file, \"w\", encoding=\"utf-8\") as out:\n",
        "            out.write(md)\n",
        "\n",
        "        print(f\"Saved: {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLzwmwfviojo",
        "outputId": "7aa0b8ed-d653-4fc7-8313-5daecda7598e"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/md_files/product_1_search.md\n",
            "Saved: /content/md_files/product_3_search.md\n",
            "Saved: /content/md_files/product_2_search.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JSON FILES TO CSV FILES MAKING: HERE THIS IS DONE FOR THE AI AGENT WHICH WILL USE A TOOL FOR RANKING AND THIS WILL BE THE DATA TO BE FED IN THE TOOL"
      ],
      "metadata": {
        "id": "4JiBaW5jjZu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CSV2NAME = {}"
      ],
      "metadata": {
        "id": "Fn4Qj_hBBU36"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reviews_to_csv(json_path: str | Path,\n",
        "                   csv_path: str | Path,\n",
        "                   rating_threshold: int = 4) -> str:      # ← return str\n",
        "    with open(json_path, encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    product     = data[\"product_results\"]\n",
        "    product_title = product.get(\"title\", \"Unknown Product\")   # ← grab title\n",
        "    reviews_root = data[\"reviews_results\"][\"reviews\"]\n",
        "    raw = [reviews_root.get(\"top_positive\"),\n",
        "           reviews_root.get(\"top_negative\"),\n",
        "          *reviews_root.get(\"customer_reviews\", [])]\n",
        "    raw = [r for r in raw if r]\n",
        "\n",
        "    rows = []\n",
        "    for r in raw:\n",
        "        text = (r.get(\"text\") or \"\").replace(\"\\n\", \" \").strip()\n",
        "        verified = \"Yes\" if \"VerifiedPurchaser\" in r.get(\"customer_type\", []) else \"No\"\n",
        "        recommended = \"Yes\" if r.get(\"rating\", 0) >= rating_threshold else \"No\"\n",
        "        upvotes = int(r.get(\"positive_feedback\") or 0)\n",
        "        downvotes = int(r.get(\"negative_feedback\") or 0)\n",
        "        rows.append([text, verified, recommended, upvotes, downvotes])\n",
        "\n",
        "    with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"Review\", \"Verified Purchaser\",\n",
        "                         \"Recommended Purchase\", \"Review Upvotes\",\n",
        "                         \"Review Downvotes\"])\n",
        "        writer.writerows(rows)\n",
        "\n",
        "    return product_title"
      ],
      "metadata": {
        "id": "fRDna3aRjzQ7"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIR  = Path(\"/content/json_uploads\")\n",
        "OUTPUT_DIR = Path(\"/content/json2csv_out\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "up22sIHJkYhs"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for json_file in glob.glob(str(INPUT_DIR / \"*.json\")):\n",
        "    json_path = Path(json_file)\n",
        "    csv_name  = json_path.stem + \".csv\"\n",
        "    csv_path  = OUTPUT_DIR / csv_name\n",
        "\n",
        "    try:\n",
        "        title = reviews_to_csv(json_path, csv_path)      # ← capture return value\n",
        "        CSV2NAME[str(csv_path)] = title                  # ← store mapping\n",
        "        print(f\"{json_path.name} → {csv_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Skipped {json_path.name}: {e}\")\n",
        "\n",
        "print(f\"\\nCSV files are saved here: {OUTPUT_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ndhqMNGjzdM",
        "outputId": "b85bca7c-7d73-4f5c-94c8-a52ee07c0d48"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "product_1_search.json → product_1_search.csv\n",
            "product_3_search.json → product_3_search.csv\n",
            "product_2_search.json → product_2_search.csv\n",
            "\n",
            "CSV files are saved here: /content/json2csv_out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "\n",
        "gemini_model = genai.GenerativeModel(\"models/gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "HNllniNikRaa"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sending the Markdown Text to LLM MODEL (HERE GEMINI) for More summarization"
      ],
      "metadata": {
        "id": "81vNnIubsshl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt_for_md_files_summarization = (\n",
        "        \"You are a highly skilled summarization assistant. You will be given the full text of a markdown file \"\n",
        "        \"containing product details and customer reviews from a Walmart product page.\\n\\n\"\n",
        "        \"Your task is to analyze this content and summarize it in the following structure using markdown format:\\n\\n\"\n",
        "        \"1. # Name of the Product\\n\"\n",
        "        \"2. # Link of the Product\\n\"\n",
        "        \"3. # Key Specifications\\n\"\n",
        "        \"   - Bullet points with important technical or physical specs\\n\"\n",
        "        \"4. # Summary of 5-Star Reviews (in 5 brief bullet points)\\n\"\n",
        "        \"5. # Summary of 4-Star Reviews (5 bullet points)\\n\"\n",
        "        \"6. # Summary of 3-Star Reviews (5 bullet points)\\n\"\n",
        "        \"7. # Summary of 2-Star Reviews (5 bullet points)\\n\"\n",
        "        \"8. # Summary of 1-Star Reviews (5 bullet points)n\\n\"\n",
        "        \"Be objective and extract actual trends and insights. Use bold, lists, and headings to keep it readable.\"\n",
        "        \"DO NOT LEAVE ANYTHING UNCHECKED\"\n",
        "    )"
      ],
      "metadata": {
        "id": "mDggry8jtfj-"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_markdown_with_gemini(md_file_path, system_prompt, model):\n",
        "    with open(md_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        markdown_text = f.read()\n",
        "\n",
        "    full_prompt = f\"{system_prompt}\\n\\n---\\n\\n{markdown_text}\"\n",
        "\n",
        "    response = model.generate_content(full_prompt)\n",
        "    result = response.text.strip()\n",
        "    display(Markdown(result))\n",
        "    return result"
      ],
      "metadata": {
        "id": "KFUSI9uosskz"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Looping through md folder\n",
        "def summarize_all_md_with_gemini(input_folder, output_folder, model):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".md\"):\n",
        "            input_path = os.path.join(input_folder, filename)\n",
        "            print(f\"Processing: {filename}\")\n",
        "\n",
        "            try:\n",
        "                summary_md = summarize_markdown_with_gemini(\n",
        "                    input_path,\n",
        "                    system_prompt_for_md_files_summarization,\n",
        "                    model\n",
        "                )\n",
        "\n",
        "                output_path = os.path.join(output_folder, filename)\n",
        "                with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                    f.write(summary_md)\n",
        "\n",
        "                print(f\"Saved: {output_path}\\n\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"error processing {filename}: {e}\\n\")"
      ],
      "metadata": {
        "id": "S7EnStYNssoC"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "source_folder_for_unsumarrized_md_files = '/content/md_files'\n",
        "target_folder_for_sumarrized_md_files = '/content/SUMMARIZED_md_files_with_LLM_MODEL_USED'\n",
        "os.makedirs(target_folder_for_sumarrized_md_files, exist_ok=True)"
      ],
      "metadata": {
        "id": "eVFS5TPEuBuh"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize_all_md_with_gemini(input_folder=source_folder_for_unsumarrized_md_files,\n",
        "                             output_folder=target_folder_for_sumarrized_md_files,\n",
        "                             model=gemini_model)\n",
        "\n",
        "# THIS IS NOT THE ANSWER, THIS IS JUST THE SUMMARIZED MARKDOWN TEXT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uy678Iqussq6",
        "outputId": "438032bb-c0c4-45fc-dd37-fb7e68d263ef"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: product_1_search.md\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# SAMSUNG Galaxy Watch 7 SM-L310N (44mm) Wi-Fi Version, AI-ready, Bluetooth\n\n# [https://www.walmart.com/ip/SAMSUNG-Galaxy-Watch-7-SM-L310N-44mm-Wi-Fi-Version-AI-ready-Bluetooth-Wellness-Tips-Heart-Rate-Tracking-Sleep-Monitor-Fitness-Tracker-Latin-Specs-Gre/11629002535](https://www.walmart.com/ip/SAMSUNG-Galaxy-Watch-7-SM-L310N-44mm-Wi-Fi-Version-AI-ready-Bluetooth-Wellness-Tips-Heart-Rate-Tracking-Sleep-Monitor-Fitness-Tracker-Latin-Specs-Gre/11629002535)\n\n# Key Specifications\n- **Size:** 44mm\n- **Connectivity:** Wi-Fi, Bluetooth (No LTE)\n- **Water Resistance:** 5ATM + IP68\n- **Processor:** Samsung's most powerful watch processor (3nm)\n- **Sensors:**  Heart rate, sleep, BIA (body composition)\n- **Watch Band Material:** Nylon\n- **Color:** Green (as reviewed)\n\n\n# Summary of 5-Star Reviews\n- Great watch at an awesome price (Latin version).\n- Works well with US phones despite being the Latin American version.\n- Easy setup, but updates may take time.\n- Highly recommended.\n- Some packaging issues reported (torn box), but product arrived intact.\n\n# Summary of 4-Star Reviews\n- Fall detection may not be reliable.\n- US time zones were unavailable during initial setup; workaround required.\n- Overall positive experience despite the shortcomings.\n\n\n# Summary of 3-Star Reviews\n- Watch is the Latin American version, not the US version.\n-  US region is not available during setup.\n\n\n# Summary of 2-Star Reviews\n- _No reviews in this category._\n\n# Summary of 1-Star Reviews\n- Several reports of receiving a watch meant for non-US countries, rendering it unusable in the US.\n- Walmart return policy issues due to short return window.\n- Shipping issues: one customer received a damaged box with no watch inside and no refund.\n- Third-party sellers are highlighted as a major source of these problems.\n- Regional limitations (Latin American version) severely restrict functionality."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/SUMMARIZED_md_files_with_LLM_MODEL_USED/product_1_search.md\n",
            "\n",
            "Processing: product_3_search.md\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Garmin vívoactive 5 Fitness-Tracking Smartwatch with Aluminum Bezel and Silicone Band, Ivory\n\n# [https://www.walmart.com/ip/Garmin-Vivoactive-5-Watch-Cream-Gold-Aluminum-Bezel-w-Ivory-Case-and-Silicone/5020233074](https://www.walmart.com/ip/Garmin-Vivoactive-5-Watch-Cream-Gold-Aluminum-Bezel-w-Ivory-Case-and-Silicone/5020233074)\n\n# Key Specifications\n- **Features:** Automatic Daylight Saving Time, Alarm Clock, Timer, Stopwatch, Touchscreen, Ambient Light Sensor, Weather Forecasts\n- **Size:** Watches only\n- **Assembled Product Weight:** 1.3 oz\n- **Battery Life:** 264 h (approx. 11 days)\n- **Brand:** Garmin\n- **Manufacturer Part Number:** 010-02862-11\n- **Color:** Ivory\n- **Watch Band Material:** Silicone\n- **Watch Band Width:** 20 mm\n- **Watch Band Length:** 180 mm\n\n\n# Summary of 5-Star Reviews\n\n- Excellent for managing energy levels and stress, particularly beneficial for individuals with chronic illnesses like POTS and myalgic encephalomyelitis.\n- Long battery life; lasting several days on a single charge.\n-  Features are easy to use and understand, even for those not tech-savvy.\n- Comfortable to wear and easy to read display.\n-  Superior to Apple Watch in terms of battery life and functionality for some users.\n\n\n# Summary of 4-Star Reviews\n\n- Battery life significantly shorter than advertised (less than 2 days).\n- Product arrived without a charger.\n- Customer service interaction is pending.\n\n\n# Summary of 3-Star Reviews\n\n- _No reviews in this category._\n\n\n# Summary of 2-Star Reviews\n\n- _No reviews in this category._\n\n\n# Summary of 1-Star Reviews\n\n- Frequent connectivity issues with the smartphone, requiring repeated pairing.\n- Inaccurate step and sleep tracking.\n- High stress levels reported by the watch, even during periods of rest.\n- Product arrived with an open box, suggesting it was a returned defective item.\n- Disappointment with Walmart's return policy."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/SUMMARIZED_md_files_with_LLM_MODEL_USED/product_3_search.md\n",
            "\n",
            "Processing: product_2_search.md\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Apple Watch Series 10 GPS 46mm Jet Black Aluminum Case with Black Sport Band - M/L\n\n# [https://www.walmart.com/ip/Apple-Watch-Series-10-GPS-46mm-Jet-Black-Aluminum-Case-with-Black-Sport-Band-M-L/11381354322](https://www.walmart.com/ip/Apple-Watch-Series-10-GPS-46mm-Jet-Black-Aluminum-Case-with-Black-Sport-Band-M-L/11381354322)\n\n# Key Specifications\n   - **Size:** 46mm, M/L band\n   - **Case Material:** Jet Black Aluminum\n   - **Band Material:** Silicone\n   - **Water Resistance:** 50 meters\n   - **Dust Resistance:** IP6X\n   - **Battery Life:** 18 hours\n   - **Features:** ECG, Fall Detection, Crash Detection, Emergency SOS, Sleep Apnea Notifications (pending FDA approval), Activity tracking, Workout tracking\n\n\n# Summary of 5-Star Reviews\n   -  Users report easy pairing with iPhones and seamless app transfer.\n   -  The larger display size is a significant improvement.\n   -  The ability to answer phone calls directly on the watch is praised.\n   -  Many reviewers find the watch very user-friendly and well-designed, typical of Apple products.\n   -  Positive feedback on the battery life, particularly compared to older models.\n\n\n# Summary of 4-Star Reviews\n   - _No 4-star reviews provided._\n\n\n# Summary of 3-Star Reviews\n   - _No 3-star reviews provided._\n\n\n# Summary of 2-Star Reviews\n   - _No 2-star reviews provided._\n\n\n# Summary of 1-Star Reviews\n   - Multiple reports of non-delivery or receiving empty boxes.\n   -  Significant issues with Walmart's customer service regarding refunds for missing or incorrect items.\n   -  One review mentions receiving a completely different, unrelated item.\n   -  Customers express extreme frustration and disappointment with Walmart's handling of these order fulfillment issues.\n   -  Strong warnings against ordering this product from Walmart due to high risk of non-delivery or receiving incorrect items."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/SUMMARIZED_md_files_with_LLM_MODEL_USED/product_2_search.md\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONVERTING Summarised MARKDOWN TO PDF FILES"
      ],
      "metadata": {
        "id": "caWE55vuiomZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "source_folder = '/content/SUMMARIZED_md_files_with_LLM_MODEL_USED'\n",
        "target_folder = '/content/converted_pdfs_from_summarized_md_files'\n",
        "os.makedirs(target_folder, exist_ok=True)"
      ],
      "metadata": {
        "id": "U25Ycb0Hiopa"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_md_to_pdf(file_path, output_folder):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.add_font('DejaVu', '', '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', uni=True)\n",
        "    pdf.set_font(\"DejaVu\", size=12)\n",
        "    pdf.set_auto_page_break(auto=True, margin=15)\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            pdf.multi_cell(0, 10, line.strip())\n",
        "\n",
        "    output_file = os.path.join(output_folder, Path(file_path).stem + '.pdf')\n",
        "    pdf.output(output_file)"
      ],
      "metadata": {
        "id": "ygXVkzzXkRHT"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# looping through the md files folder and then using the above functions to make PDFs and then stroing it in a folder 'converted_pdfs_from_md_and_txt'\n",
        "\n",
        "# first, stroing all the paths of md and txt files in a list\n",
        "md_paths = []\n",
        "for root, dirs, files in os.walk(source_folder):\n",
        "    for file in files:\n",
        "        if file.endswith('.md'):\n",
        "            file_path = os.path.join(root, file)\n",
        "            md_paths.append(file_path)\n",
        "            print(f\"Loading: {file_path}\") #to check if the function is correctly loading all the files with .md and .txt extension or not?"
      ],
      "metadata": {
        "id": "TlgENBDIkRPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03e4170d-7a0e-4b8a-8b2c-ea650efab44c"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading: /content/SUMMARIZED_md_files_with_LLM_MODEL_USED/product_1_search.md\n",
            "Loading: /content/SUMMARIZED_md_files_with_LLM_MODEL_USED/product_3_search.md\n",
            "Loading: /content/SUMMARIZED_md_files_with_LLM_MODEL_USED/product_2_search.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for file_path in md_paths:\n",
        "    if file_path.endswith('.md'):\n",
        "        convert_md_to_pdf(file_path, target_folder)\n",
        "\n",
        "print(f\"a total of {len(md_paths)} .md files have been converted to PDFs and saved in:\", target_folder)"
      ],
      "metadata": {
        "id": "E_uwL064kRSL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c71b8f35-5dec-4ace-d18c-eaca3970fa46"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a total of 3 .md files have been converted to PDFs and saved in: /content/converted_pdfs_from_summarized_md_files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the PDF Documents now"
      ],
      "metadata": {
        "id": "_CvydNv6IhlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_extractor = URLExtract()\n",
        "# Accept ftp://, maps.google, drive links, ipfs, etc.\n",
        "URL_REGEX = re.compile(\n",
        "    r'''((?:http|ftp)s?://[^\\s<>\"'\\]\\)]{4,})''',\n",
        "    flags=re.IGNORECASE)\n",
        "\n",
        "def clean_and_tag_urls(text:str)->tuple[str,list]:\n",
        "    \"\"\"\n",
        "    1. Find every URL with a fast heuristic (regex + urlextract fallback)\n",
        "    2. Deduplicate + preserve original casing\n",
        "    3. Return the clean text and the url list\n",
        "    \"\"\"\n",
        "    # direct regex hits\n",
        "    urls = set(m.group(0).strip(').,]') for m in URL_REGEX.finditer(text))\n",
        "    # urlextract sometimes catches things the regex missed (maps links, etc.)\n",
        "    urls.update(url_extractor.find_urls(text))\n",
        "\n",
        "    urls = sorted(urls)\n",
        "    if urls:\n",
        "        tagged = text.rstrip() + \"\\n\\n<<URLS>>\\n\" + \"\\n\".join(urls)\n",
        "    else:\n",
        "        tagged = text\n",
        "    return tagged, urls\n",
        "\n",
        "\n",
        "def pdf_pages_with_real_links(pdf_path:str)->list[Document]:\n",
        "    \"\"\"\n",
        "    Read a PDF with PyMuPDF, grab the *annotation links* that are not visible\n",
        "    in the raw text, and build LangChain Documents whose .metadata\n",
        "    contains a list of urls on that page.\n",
        "    \"\"\"\n",
        "    pages=[]\n",
        "    with fitz.open(pdf_path) as doc:\n",
        "        for page_index in range(len(doc)):\n",
        "            p = doc.load_page(page_index)\n",
        "\n",
        "            # -- 1. text that PyMuPDF sees\n",
        "            raw_text = p.get_text(\"text\")\n",
        "\n",
        "            # -- 2. links hidden in annotations\n",
        "            ann_links = [l.get(\"uri\") for l in p.get_links() if l.get(\"uri\")]\n",
        "            ann_links = [u for u in ann_links if u]          # drop Nones\n",
        "\n",
        "            # -- 3. merge + tag\n",
        "            merged_text, text_links = clean_and_tag_urls(raw_text)\n",
        "            all_links = sorted(set(text_links).union(ann_links))\n",
        "\n",
        "            pages.append(\n",
        "                Document(\n",
        "                    page_content = merged_text,\n",
        "                    metadata     = {\n",
        "                        \"source\"   : pathlib.Path(pdf_path).name,\n",
        "                        \"page\"     : page_index+1,\n",
        "                        \"links\"    : all_links\n",
        "                    }\n",
        "                )\n",
        "            )\n",
        "    return pages"
      ],
      "metadata": {
        "id": "uqCv7MUzIiLS"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### begining of rag dataset"
      ],
      "metadata": {
        "id": "E3JQXNLCLzQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load every PDF in the drive folder with the new loader\n",
        "\n",
        "rag_dataset_path = '/content/converted_pdfs_from_summarized_md_files'\n",
        "docs = []\n",
        "\n",
        "for root, dirs, files in os.walk(rag_dataset_path):\n",
        "    for f in files:\n",
        "        if f.lower().endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(root, f)\n",
        "            docs.extend(pdf_pages_with_real_links(pdf_path))\n",
        "            print(f\"Loading: {pdf_path}\") #to see and check if all pdfs are considered or not"
      ],
      "metadata": {
        "id": "6Owxgiv0IiQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8274706d-daf8-4c73-a136-f2075f41bdf0"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading: /content/converted_pdfs_from_summarized_md_files/product_2_search.pdf\n",
            "Loading: /content/converted_pdfs_from_summarized_md_files/product_1_search.pdf\n",
            "Loading: /content/converted_pdfs_from_summarized_md_files/product_3_search.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Loaded {len(docs)} pages and preserved hyperlinks.\\n\")"
      ],
      "metadata": {
        "id": "Ijgy26FsJg_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f122a6e-5207-47e3-f79c-da09e85760fc"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 7 pages and preserved hyperlinks.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "id": "2hVptrMGJhaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a36b8c16-11c3-4803-88be-74c6ce3ab984"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'product_2_search.pdf', 'page': 1, 'links': ['https://www.walmart.com/ip/Apple-Watch-', 'https://www.walmart.com/ip/Apple-Watch-Series-10-GPS-46mm-Jet-Black-Aluminum-Ca']}, page_content='# Apple Watch Series 10 GPS 46mm Jet Black Aluminum Case with Black Sport Band -\\nM/L\\n#\\n[https://www.walmart.com/ip/Apple-Watch-Series-10-GPS-46mm-Jet-Black-Aluminum-Ca\\nse-with-Black-Sport-Band-M-L/11381354322](https://www.walmart.com/ip/Apple-Watch-\\nSeries-10-GPS-46mm-Jet-Black-Aluminum-Case-with-Black-Sport-Band-M-L/1138135432\\n2)\\n# Key Specifications\\n- **Size:** 46mm, M/L band\\n- **Case Material:** Jet Black Aluminum\\n- **Band Material:** Silicone\\n- **Water Resistance:** 50 meters\\n- **Dust Resistance:** IP6X\\n- **Battery Life:** 18 hours\\n-  **Features:**  ECG,  Fall  Detection,  Crash  Detection,  Emergency  SOS,  Sleep  Apnea\\nNotifications (pending FDA approval), Activity tracking, Workout tracking\\n# Summary of 5-Star Reviews\\n-  Users report easy pairing with iPhones and seamless app transfer.\\n-  The larger display size is a significant improvement.\\n-  The ability to answer phone calls directly on the watch is praised.\\n-  Many reviewers find the watch very user-friendly and well-designed, typical of Apple\\nproducts.\\n-  Positive feedback on the battery life, particularly compared to older models.\\n\\n<<URLS>>\\nhttps://www.walmart.com/ip/Apple-Watch-\\nhttps://www.walmart.com/ip/Apple-Watch-Series-10-GPS-46mm-Jet-Black-Aluminum-Ca'),\n",
              " Document(metadata={'source': 'product_2_search.pdf', 'page': 2, 'links': []}, page_content=\"# Summary of 4-Star Reviews\\n- _No 4-star reviews provided._\\n# Summary of 3-Star Reviews\\n- _No 3-star reviews provided._\\n# Summary of 2-Star Reviews\\n- _No 2-star reviews provided._\\n# Summary of 1-Star Reviews\\n- Multiple reports of non-delivery or receiving empty boxes.\\n-  Significant issues with Walmart's customer service regarding refunds for missing or\\nincorrect items.\\n-  One review mentions receiving a completely different, unrelated item.\\n-  Customers express extreme frustration and disappointment with Walmart's handling\\nof these order fulfillment issues.\\n-   Strong  warnings  against  ordering  this  product  from  Walmart  due  to  high  risk  of\\nnon-delivery or receiving incorrect items.\\n\"),\n",
              " Document(metadata={'source': 'product_1_search.pdf', 'page': 1, 'links': ['https://www.walmart.com/ip/SAMSUNG-Galaxy-Watch-7-S', 'https://www.walmart.com/ip/SAMSUNG-Galaxy-Watch-7-SM-L310N-44mm-Wi-Fi-Version']}, page_content=\"# SAMSUNG Galaxy Watch 7 SM-L310N (44mm) Wi-Fi Version, AI-ready, Bluetooth\\n#\\n[https://www.walmart.com/ip/SAMSUNG-Galaxy-Watch-7-SM-L310N-44mm-Wi-Fi-Version\\n-AI-ready-Bluetooth-Wellness-Tips-Heart-Rate-Tracking-Sleep-Monitor-Fitness-Tracker-La\\ntin-Specs-Gre/11629002535](https://www.walmart.com/ip/SAMSUNG-Galaxy-Watch-7-S\\nM-L310N-44mm-Wi-Fi-Version-AI-ready-Bluetooth-Wellness-Tips-Heart-Rate-Tracking-Sle\\nep-Monitor-Fitness-Tracker-Latin-Specs-Gre/11629002535)\\n# Key Specifications\\n- **Size:** 44mm\\n- **Connectivity:** Wi-Fi, Bluetooth (No LTE)\\n- **Water Resistance:** 5ATM + IP68\\n- **Processor:** Samsung's most powerful watch processor (3nm)\\n- **Sensors:**  Heart rate, sleep, BIA (body composition)\\n- **Watch Band Material:** Nylon\\n- **Color:** Green (as reviewed)\\n# Summary of 5-Star Reviews\\n- Great watch at an awesome price (Latin version).\\n- Works well with US phones despite being the Latin American version.\\n- Easy setup, but updates may take time.\\n- Highly recommended.\\n- Some packaging issues reported (torn box), but product arrived intact.\\n# Summary of 4-Star Reviews\\n\\n<<URLS>>\\nhttps://www.walmart.com/ip/SAMSUNG-Galaxy-Watch-7-S\\nhttps://www.walmart.com/ip/SAMSUNG-Galaxy-Watch-7-SM-L310N-44mm-Wi-Fi-Version\"),\n",
              " Document(metadata={'source': 'product_1_search.pdf', 'page': 2, 'links': []}, page_content='- Fall detection may not be reliable.\\n- US time zones were unavailable during initial setup; workaround required.\\n- Overall positive experience despite the shortcomings.\\n# Summary of 3-Star Reviews\\n- Watch is the Latin American version, not the US version.\\n-  US region is not available during setup.\\n# Summary of 2-Star Reviews\\n- _No reviews in this category._\\n# Summary of 1-Star Reviews\\n- Several reports of receiving a watch meant for non-US countries, rendering it unusable\\nin the US.\\n- Walmart return policy issues due to short return window.\\n- Shipping issues: one customer received a damaged box with no watch inside and no\\nrefund.\\n- Third-party sellers are highlighted as a major source of these problems.\\n- Regional limitations (Latin American version) severely restrict functionality.\\n'),\n",
              " Document(metadata={'source': 'product_3_search.pdf', 'page': 1, 'links': ['https://www.walmart.com/ip/Garmin-Vivoactive', 'https://www.walmart.com/ip/Garmin-Vivoactive-5-Watch-Cream-Gold-Aluminum-Bezel-']}, page_content='# Garmin vívoactive 5 Fitness-Tracking Smartwatch with Aluminum Bezel and Silicone\\nBand, Ivory\\n#\\n[https://www.walmart.com/ip/Garmin-Vivoactive-5-Watch-Cream-Gold-Aluminum-Bezel-\\nw-Ivory-Case-and-Silicone/5020233074](https://www.walmart.com/ip/Garmin-Vivoactive\\n-5-Watch-Cream-Gold-Aluminum-Bezel-w-Ivory-Case-and-Silicone/5020233074)\\n# Key Specifications\\n-  **Features:**  Automatic  Daylight  Saving  Time,  Alarm  Clock,  Timer,  Stopwatch,\\nTouchscreen, Ambient Light Sensor, Weather Forecasts\\n- **Size:** Watches only\\n- **Assembled Product Weight:** 1.3 oz\\n- **Battery Life:** 264 h (approx. 11 days)\\n- **Brand:** Garmin\\n- **Manufacturer Part Number:** 010-02862-11\\n- **Color:** Ivory\\n- **Watch Band Material:** Silicone\\n- **Watch Band Width:** 20 mm\\n- **Watch Band Length:** 180 mm\\n# Summary of 5-Star Reviews\\n- Excellent for managing energy levels and stress, particularly beneficial for individuals\\nwith chronic illnesses like POTS and myalgic encephalomyelitis.\\n- Long battery life; lasting several days on a single charge.\\n\\n<<URLS>>\\nhttps://www.walmart.com/ip/Garmin-Vivoactive\\nhttps://www.walmart.com/ip/Garmin-Vivoactive-5-Watch-Cream-Gold-Aluminum-Bezel-'),\n",
              " Document(metadata={'source': 'product_3_search.pdf', 'page': 2, 'links': []}, page_content='-  Features are easy to use and understand, even for those not tech-savvy.\\n- Comfortable to wear and easy to read display.\\n-  Superior to Apple Watch in terms of battery life and functionality for some users.\\n# Summary of 4-Star Reviews\\n- Battery life significantly shorter than advertised (less than 2 days).\\n- Product arrived without a charger.\\n- Customer service interaction is pending.\\n# Summary of 3-Star Reviews\\n- _No reviews in this category._\\n# Summary of 2-Star Reviews\\n- _No reviews in this category._\\n# Summary of 1-Star Reviews\\n- Frequent connectivity issues with the smartphone, requiring repeated pairing.\\n- Inaccurate step and sleep tracking.\\n- High stress levels reported by the watch, even during periods of rest.\\n'),\n",
              " Document(metadata={'source': 'product_3_search.pdf', 'page': 3, 'links': []}, page_content=\"- Product arrived with an open box, suggesting it was a returned defective item.\\n- Disappointment with Walmart's return policy.\\n\")]"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0].page_content) #this will load the first page of the first pdf document"
      ],
      "metadata": {
        "id": "d4C6PrllJhnj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "587a0714-945c-46be-b023-23b3fabd5498"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Apple Watch Series 10 GPS 46mm Jet Black Aluminum Case with Black Sport Band -\n",
            "M/L\n",
            "#\n",
            "[https://www.walmart.com/ip/Apple-Watch-Series-10-GPS-46mm-Jet-Black-Aluminum-Ca\n",
            "se-with-Black-Sport-Band-M-L/11381354322](https://www.walmart.com/ip/Apple-Watch-\n",
            "Series-10-GPS-46mm-Jet-Black-Aluminum-Case-with-Black-Sport-Band-M-L/1138135432\n",
            "2)\n",
            "# Key Specifications\n",
            "- **Size:** 46mm, M/L band\n",
            "- **Case Material:** Jet Black Aluminum\n",
            "- **Band Material:** Silicone\n",
            "- **Water Resistance:** 50 meters\n",
            "- **Dust Resistance:** IP6X\n",
            "- **Battery Life:** 18 hours\n",
            "-  **Features:**  ECG,  Fall  Detection,  Crash  Detection,  Emergency  SOS,  Sleep  Apnea\n",
            "Notifications (pending FDA approval), Activity tracking, Workout tracking\n",
            "# Summary of 5-Star Reviews\n",
            "-  Users report easy pairing with iPhones and seamless app transfer.\n",
            "-  The larger display size is a significant improvement.\n",
            "-  The ability to answer phone calls directly on the watch is praised.\n",
            "-  Many reviewers find the watch very user-friendly and well-designed, typical of Apple\n",
            "products.\n",
            "-  Positive feedback on the battery life, particularly compared to older models.\n",
            "\n",
            "<<URLS>>\n",
            "https://www.walmart.com/ip/Apple-Watch-\n",
            "https://www.walmart.com/ip/Apple-Watch-Series-10-GPS-46mm-Jet-Black-Aluminum-Ca\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the Chunks from the PDFs using nomic-embedder"
      ],
      "metadata": {
        "id": "LS6rUpNcyNot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt_1 = \"\"\"\n",
        "You are Marty, a neutral and detail-oriented AI assistant, for Walmart. Your task is to analyze the provided product content — including specifications, descriptions, and user reviews — and generate a comprehensive, structured summary.\n",
        "\n",
        "Break down your analysis into the following sections:\n",
        "1. **Key Specifications** – Extract core technical details such as dimensions, features, compatibility, materials, performance, battery life, etc.\n",
        "2. **Pros** – Summarize positive review sentiments and commonly appreciated features or experiences.\n",
        "3. **Cons** – Summarize negative review sentiments and commonly reported issues or drawbacks.\n",
        "4. **Use Case Suitability** – Describe the ideal user profile or context for which this product is best suited.\n",
        "5. **Overall Impression** – Provide a concise, balanced conclusion on the product based on both specs and user reviws and stars given.\n",
        "\n",
        "\"BE To the Point, detailed BUT DO NOT BE OVER-DETAILED AND DO NOT BE VERBOSE\"\n",
        "\n",
        "Also Give the Walart buy LINKS as it is\n",
        "\n",
        "Stay objective and avoid personal opinions. Be concise, factual, and structured in your response.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_YTuFnUvKkus"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt_2 = \"\"\"\n",
        "You are Marty a product comparison assistant for Walmart.\n",
        "\n",
        "Your task is to compare two products using the provided content, which includes technical specifications, descriptions, and summaries of user reviews.\n",
        "\n",
        "Please follow this simple structure and keep the language clear, neutral, and to-the-point:\n",
        "\n",
        "1. **Comparison Table** – Side-by-side summary of important features such as build, performance, display, battery, pricing, etc.\n",
        "\n",
        "2. **User Review Summary** – For each product, briefly summarize the main positives and negatives based on customer feedback and star ratings.\n",
        "\n",
        "3. **Strengths & Weaknesses** – Highlight what stands out for each product, both in terms of specs and user satisfaction.\n",
        "\n",
        "4. **Use Case Recommendation** – Suggest which product is better suited for what kind of user or usage scenario.\n",
        "\n",
        "5. **Final Verdict** – Provide a short, fair conclusion comparing the two products. Be objective and avoid unnecessary detail.\n",
        "\n",
        "Also include any **Walmart product links** exactly as they appear in the content.\n",
        "\n",
        "Use markdown formatting with headings and bullet points where appropriate.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "GZTxMSdgLdUB"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt_3 = \"\"\"\n",
        "You are Marty,  a strict, unbiased product-ranking AI agent.\n",
        "\n",
        "You MUST use the tools you are given — especially `rank_multiple_products` — to retrieve review data for all products.\n",
        "\n",
        "Rank products from best to worst based on actual review content only. Avoid assumptions, specs, or external knowledge.\n",
        "\n",
        "Your rankings and reasoning MUST be entirely based on retrieved customer feedback: common sentiments, praises, complaints, and patterns found in the text.\n",
        "\n",
        "Never fabricate product strengths or weaknesses — rely only on what the dataset reveals. If you lack enough information, clearly mention it.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "QyI2XDiPL1h2"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(docs)):\n",
        "    docs[i].page_content = re.sub(r\"(https?://\\S+)\", r\"\\n\\1\\n\", docs[i].page_content)\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=2000,\n",
        "    chunk_overlap=1000,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \"http\", \" \", \"\"]\n",
        ")\n",
        "\n",
        "chunks = splitter.split_documents(docs)\n"
      ],
      "metadata": {
        "id": "63Eh6T_r6nbH"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks"
      ],
      "metadata": {
        "id": "n-DFiRwlNn5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca274e3f-f756-466b-ca42-25b9d2176f60"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'product_2_search.pdf', 'page': 1, 'links': ['https://www.walmart.com/ip/Apple-Watch-', 'https://www.walmart.com/ip/Apple-Watch-Series-10-GPS-46mm-Jet-Black-Aluminum-Ca']}, page_content='# Apple Watch Series 10 GPS 46mm Jet Black Aluminum Case with Black Sport Band -\\nM/L\\n#\\n[\\nhttps://www.walmart.com/ip/Apple-Watch-Series-10-GPS-46mm-Jet-Black-Aluminum-Ca\\n\\nse-with-Black-Sport-Band-M-L/11381354322](\\nhttps://www.walmart.com/ip/Apple-Watch-\\n\\nSeries-10-GPS-46mm-Jet-Black-Aluminum-Case-with-Black-Sport-Band-M-L/1138135432\\n2)\\n# Key Specifications\\n- **Size:** 46mm, M/L band\\n- **Case Material:** Jet Black Aluminum\\n- **Band Material:** Silicone\\n- **Water Resistance:** 50 meters\\n- **Dust Resistance:** IP6X\\n- **Battery Life:** 18 hours\\n-  **Features:**  ECG,  Fall  Detection,  Crash  Detection,  Emergency  SOS,  Sleep  Apnea\\nNotifications (pending FDA approval), Activity tracking, Workout tracking\\n# Summary of 5-Star Reviews\\n-  Users report easy pairing with iPhones and seamless app transfer.\\n-  The larger display size is a significant improvement.\\n-  The ability to answer phone calls directly on the watch is praised.\\n-  Many reviewers find the watch very user-friendly and well-designed, typical of Apple\\nproducts.\\n-  Positive feedback on the battery life, particularly compared to older models.\\n\\n<<URLS>>\\n\\nhttps://www.walmart.com/ip/Apple-Watch-\\n\\n\\nhttps://www.walmart.com/ip/Apple-Watch-Series-10-GPS-46mm-Jet-Black-Aluminum-Ca'),\n",
              " Document(metadata={'source': 'product_2_search.pdf', 'page': 2, 'links': []}, page_content=\"# Summary of 4-Star Reviews\\n- _No 4-star reviews provided._\\n# Summary of 3-Star Reviews\\n- _No 3-star reviews provided._\\n# Summary of 2-Star Reviews\\n- _No 2-star reviews provided._\\n# Summary of 1-Star Reviews\\n- Multiple reports of non-delivery or receiving empty boxes.\\n-  Significant issues with Walmart's customer service regarding refunds for missing or\\nincorrect items.\\n-  One review mentions receiving a completely different, unrelated item.\\n-  Customers express extreme frustration and disappointment with Walmart's handling\\nof these order fulfillment issues.\\n-   Strong  warnings  against  ordering  this  product  from  Walmart  due  to  high  risk  of\\nnon-delivery or receiving incorrect items.\"),\n",
              " Document(metadata={'source': 'product_1_search.pdf', 'page': 1, 'links': ['https://www.walmart.com/ip/SAMSUNG-Galaxy-Watch-7-S', 'https://www.walmart.com/ip/SAMSUNG-Galaxy-Watch-7-SM-L310N-44mm-Wi-Fi-Version']}, page_content=\"# SAMSUNG Galaxy Watch 7 SM-L310N (44mm) Wi-Fi Version, AI-ready, Bluetooth\\n#\\n[\\nhttps://www.walmart.com/ip/SAMSUNG-Galaxy-Watch-7-SM-L310N-44mm-Wi-Fi-Version\\n\\n-AI-ready-Bluetooth-Wellness-Tips-Heart-Rate-Tracking-Sleep-Monitor-Fitness-Tracker-La\\ntin-Specs-Gre/11629002535](\\nhttps://www.walmart.com/ip/SAMSUNG-Galaxy-Watch-7-S\\n\\nM-L310N-44mm-Wi-Fi-Version-AI-ready-Bluetooth-Wellness-Tips-Heart-Rate-Tracking-Sle\\nep-Monitor-Fitness-Tracker-Latin-Specs-Gre/11629002535)\\n# Key Specifications\\n- **Size:** 44mm\\n- **Connectivity:** Wi-Fi, Bluetooth (No LTE)\\n- **Water Resistance:** 5ATM + IP68\\n- **Processor:** Samsung's most powerful watch processor (3nm)\\n- **Sensors:**  Heart rate, sleep, BIA (body composition)\\n- **Watch Band Material:** Nylon\\n- **Color:** Green (as reviewed)\\n# Summary of 5-Star Reviews\\n- Great watch at an awesome price (Latin version).\\n- Works well with US phones despite being the Latin American version.\\n- Easy setup, but updates may take time.\\n- Highly recommended.\\n- Some packaging issues reported (torn box), but product arrived intact.\\n# Summary of 4-Star Reviews\\n\\n<<URLS>>\\n\\nhttps://www.walmart.com/ip/SAMSUNG-Galaxy-Watch-7-S\\n\\n\\nhttps://www.walmart.com/ip/SAMSUNG-Galaxy-Watch-7-SM-L310N-44mm-Wi-Fi-Version\"),\n",
              " Document(metadata={'source': 'product_1_search.pdf', 'page': 2, 'links': []}, page_content='- Fall detection may not be reliable.\\n- US time zones were unavailable during initial setup; workaround required.\\n- Overall positive experience despite the shortcomings.\\n# Summary of 3-Star Reviews\\n- Watch is the Latin American version, not the US version.\\n-  US region is not available during setup.\\n# Summary of 2-Star Reviews\\n- _No reviews in this category._\\n# Summary of 1-Star Reviews\\n- Several reports of receiving a watch meant for non-US countries, rendering it unusable\\nin the US.\\n- Walmart return policy issues due to short return window.\\n- Shipping issues: one customer received a damaged box with no watch inside and no\\nrefund.\\n- Third-party sellers are highlighted as a major source of these problems.\\n- Regional limitations (Latin American version) severely restrict functionality.'),\n",
              " Document(metadata={'source': 'product_3_search.pdf', 'page': 1, 'links': ['https://www.walmart.com/ip/Garmin-Vivoactive', 'https://www.walmart.com/ip/Garmin-Vivoactive-5-Watch-Cream-Gold-Aluminum-Bezel-']}, page_content='# Garmin vívoactive 5 Fitness-Tracking Smartwatch with Aluminum Bezel and Silicone\\nBand, Ivory\\n#\\n[\\nhttps://www.walmart.com/ip/Garmin-Vivoactive-5-Watch-Cream-Gold-Aluminum-Bezel-\\n\\nw-Ivory-Case-and-Silicone/5020233074](\\nhttps://www.walmart.com/ip/Garmin-Vivoactive\\n\\n-5-Watch-Cream-Gold-Aluminum-Bezel-w-Ivory-Case-and-Silicone/5020233074)\\n# Key Specifications\\n-  **Features:**  Automatic  Daylight  Saving  Time,  Alarm  Clock,  Timer,  Stopwatch,\\nTouchscreen, Ambient Light Sensor, Weather Forecasts\\n- **Size:** Watches only\\n- **Assembled Product Weight:** 1.3 oz\\n- **Battery Life:** 264 h (approx. 11 days)\\n- **Brand:** Garmin\\n- **Manufacturer Part Number:** 010-02862-11\\n- **Color:** Ivory\\n- **Watch Band Material:** Silicone\\n- **Watch Band Width:** 20 mm\\n- **Watch Band Length:** 180 mm\\n# Summary of 5-Star Reviews\\n- Excellent for managing energy levels and stress, particularly beneficial for individuals\\nwith chronic illnesses like POTS and myalgic encephalomyelitis.\\n- Long battery life; lasting several days on a single charge.\\n\\n<<URLS>>\\n\\nhttps://www.walmart.com/ip/Garmin-Vivoactive\\n\\n\\nhttps://www.walmart.com/ip/Garmin-Vivoactive-5-Watch-Cream-Gold-Aluminum-Bezel-'),\n",
              " Document(metadata={'source': 'product_3_search.pdf', 'page': 2, 'links': []}, page_content='-  Features are easy to use and understand, even for those not tech-savvy.\\n- Comfortable to wear and easy to read display.\\n-  Superior to Apple Watch in terms of battery life and functionality for some users.\\n# Summary of 4-Star Reviews\\n- Battery life significantly shorter than advertised (less than 2 days).\\n- Product arrived without a charger.\\n- Customer service interaction is pending.\\n# Summary of 3-Star Reviews\\n- _No reviews in this category._\\n# Summary of 2-Star Reviews\\n- _No reviews in this category._\\n# Summary of 1-Star Reviews\\n- Frequent connectivity issues with the smartphone, requiring repeated pairing.\\n- Inaccurate step and sleep tracking.\\n- High stress levels reported by the watch, even during periods of rest.'),\n",
              " Document(metadata={'source': 'product_3_search.pdf', 'page': 3, 'links': []}, page_content=\"- Product arrived with an open box, suggesting it was a returned defective item.\\n- Disappointment with Walmart's return policy.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "token_counts = [len(encoding.encode(chunk.page_content)) for chunk in chunks]\n",
        "print(f\"The list of token counts per chunk: {token_counts}\")\n",
        "print(f\"Total tokens across all chunks: {sum(token_counts)}\")"
      ],
      "metadata": {
        "id": "VEGOILEt6ob1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ceec261-a433-4d0d-eb5d-444dd34093b1"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The list of token counts per chunk: [341, 157, 371, 162, 338, 160, 25]\n",
            "Total tokens across all chunks: 1554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using nomic-embed-text model\n",
        "nomic_model_name = \"nomic-ai/nomic-embed-text-v1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(nomic_model_name, trust_remote_code=True)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "nomic_model = AutoModel.from_pretrained(nomic_model_name, trust_remote_code=True).to(device)"
      ],
      "metadata": {
        "id": "pNfsTwbh6ogc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6e98d43-a5a6-4480-b411-9863ad30d5b4"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.nomic-ai.nomic-bert-2048.7710840340a098cfb869c4f65e87cf2b1b70caca.modeling_hf_nomic_bert:<All keys matched successfully>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_query_nomic(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = nomic_model(**inputs)\n",
        "        embedding = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
        "    return embedding"
      ],
      "metadata": {
        "id": "HEDg_x7e6okr"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and Chunking the Documnets"
      ],
      "metadata": {
        "id": "Ync0BPx7QQtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_documents(folder):\n",
        "    docs = []\n",
        "    for root, _, files in os.walk(folder):\n",
        "        for f in files:\n",
        "            if f.lower().endswith(\".pdf\"):\n",
        "                path = os.path.join(root, f)\n",
        "                docs.extend(pdf_pages_with_real_links(path))\n",
        "                print(f\"Loaded: {path}\")\n",
        "    return docs"
      ],
      "metadata": {
        "id": "REnVvvVM6opU"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FAISS Indexing with Nomic Embeddings"
      ],
      "metadata": {
        "id": "86RPk18hRQ_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def index_with_nomic(docs):\n",
        "    vectors = [embed_query_nomic(d.page_content) for d in docs]\n",
        "    dim = len(vectors[0])\n",
        "    index = faiss.IndexFlatIP(dim)\n",
        "    index.add(np.array(vectors))\n",
        "    return index, docs"
      ],
      "metadata": {
        "id": "RgRJv-rz6ota"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieval & Gemini Answering"
      ],
      "metadata": {
        "id": "YdPofN6RRdoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_top_k(index, docs, k=10):\n",
        "    all_vectors = np.array([embed_query_nomic(d.page_content) for d in docs])\n",
        "    D, I = index.search(all_vectors, k)\n",
        "    retrieved = [docs[i] for row in I for i in row if i < len(docs)]\n",
        "    return retrieved\n",
        "\n",
        "def run_rag(index, docs, prompt):\n",
        "    retrieved = retrieve_top_k(index, docs, k=5)\n",
        "    combined = \"\\n\\n--- SOURCE SPLIT ---\\n\\n\".join(d.page_content for d in retrieved)\n",
        "    final_prompt = f\"{prompt}\\n\\n{combined}\"\n",
        "    response = gemini_model.generate_content(final_prompt)\n",
        "\n",
        "    clean_output = response.text.replace(\"\\\\n\", \"\\n\").replace(\"\\\\'\", \"'\").strip()\n",
        "\n",
        "    # display(Markdown(clean_output))\n",
        "    return clean_output"
      ],
      "metadata": {
        "id": "SRWL9GrrRZnb"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agentic AI setup for 3 or more than 3 json files from here"
      ],
      "metadata": {
        "id": "7AqfoV5Rfois"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for using RAG Here\n",
        "_global_docs  = load_documents(rag_dataset_path)\n",
        "_global_index, _ = index_with_nomic(_global_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1ZRQD3-GV7w",
        "outputId": "eb4e0299-7af8-41bc-88ba-0a0917749a4f"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: /content/converted_pdfs_from_summarized_md_files/product_2_search.pdf\n",
            "Loaded: /content/converted_pdfs_from_summarized_md_files/product_1_search.pdf\n",
            "Loaded: /content/converted_pdfs_from_summarized_md_files/product_3_search.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_for_query(index, docs, query: str, k: int = 5):\n",
        "    \"\"\"Embed <query>, perform FAISS search, return k Docs.\"\"\"\n",
        "    q_vec = embed_query_nomic(query)\n",
        "    D, I = index.search(np.array([q_vec]).astype('float32'), k)\n",
        "    return [docs[i] for i in I[0]]\n",
        "\n",
        "def rag_snippets(product_name: str, n_chunks: int = 5) -> str:\n",
        "    \"\"\"\n",
        "    Return 3-5 verbatim customer sentences (positive AND negative) that mention\n",
        "    <product_name>, extracted from the RAG corpus.\n",
        "    \"\"\"\n",
        "    pages = retrieve_for_query(_global_index, _global_docs,\n",
        "                               product_name, k=n_chunks)\n",
        "\n",
        "    if not pages:\n",
        "        return \"No relevant customer text found.\"\n",
        "\n",
        "    combined = \"\\n\\n--- PAGE SPLIT ---\\n\\n\".join(p.page_content for p in pages)\n",
        "\n",
        "    prompt = (\n",
        "        f\"From the text below, quote 3-5 **verbatim** customer sentences \"\n",
        "        f\"(both positive and negative) about **{product_name}**. \"\n",
        "        \"Put them inside a single block of triple back-ticks.\\n\\n\"\n",
        "        f\"{combined}\"\n",
        "    )\n",
        "    return gemini_model.generate_content(prompt).text.strip()"
      ],
      "metadata": {
        "id": "epwnwl9UJS9Y"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "STOP_WORDS = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "ntyIrhdqhHAt"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing of the CSV Files if any"
      ],
      "metadata": {
        "id": "9R99rUd4hHWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text:str) -> str:\n",
        "    \"\"\"Clean, remove stop-words, lemmatise – exactly as during training.\"\"\"\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", str(text).lower())\n",
        "    tokens = [w for w in text.split() if w not in STOP_WORDS]\n",
        "    tokens = word_tokenize(\" \".join(tokens))\n",
        "    pos_map = {\"J\":wordnet.ADJ,\"N\":wordnet.NOUN,\"V\":wordnet.VERB,\"R\":wordnet.ADV}\n",
        "    return \" \".join(\n",
        "        lemmatizer.lemmatize(tok, pos_map.get(tag[0].upper(), wordnet.NOUN))\n",
        "        for tok, (_, tag) in zip(tokens, nltk.pos_tag(tokens))\n",
        "    )"
      ],
      "metadata": {
        "id": "yk8AeBD5mbx5"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def topic_flags(text:str) -> list[int]:\n",
        "    t = text.lower()\n",
        "    return [\n",
        "        int(any(k in t for k in [\"service\",\"support\",\"customer\"])),\n",
        "        int(any(k in t for k in [\"delivery\",\"shipping\",\"late\"])),\n",
        "        int(any(k in t for k in [\"account\",\"login\",\"password\"])),\n",
        "        int(any(k in t for k in [\"refund\",\"return\",\"money\"])),\n",
        "    ]"
      ],
      "metadata": {
        "id": "jqJzXdl5mb2j"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def numeric_feats(proc:str, raw:str, up:int, down:int) -> list[float]:\n",
        "    return [\n",
        "        *topic_flags(proc),\n",
        "        len(proc),\n",
        "        sum(c.isupper() for c in raw) / max(len(raw),1),\n",
        "        raw.count(\"!\"),\n",
        "        raw.count(\"?\"),\n",
        "    ]"
      ],
      "metadata": {
        "id": "sT8ktfSTmb8-"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PRIDICTION FROM THE CSV FILE DATA"
      ],
      "metadata": {
        "id": "rqSjdnbEmcDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_dataframe(df:pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Adds pred_label + probability columns to the incoming df.\"\"\"\n",
        "    docs, feats = [], []\n",
        "    for _, r in df.iterrows():\n",
        "        raw  = str(r[\"Review\"])\n",
        "        proc = preprocess(raw)\n",
        "        docs.append(proc)\n",
        "        feats.append(numeric_feats(proc, raw,\n",
        "                                   int(r[\"Review Upvotes\"]), int(r[\"Review Downvotes\"])))\n",
        "    X_text = vectorizer.transform(docs).toarray()\n",
        "    X_num  = scaler.transform(np.array(feats))\n",
        "    X      = np.hstack([X_text, X_num])\n",
        "\n",
        "    lbls  = model.predict(X)\n",
        "    probs = model.predict_proba(X)\n",
        "\n",
        "    df = df.copy()\n",
        "    df[\"pred_label\"]    = lbls\n",
        "    df[\"prob_negative\"] = probs[:,0]\n",
        "    df[\"prob_neutral\"]  = probs[:,1]\n",
        "    df[\"prob_positive\"] = probs[:,2]\n",
        "    return df"
      ],
      "metadata": {
        "id": "6eQjT9hkm0Qq"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _nice_name_from_filename(csv_path: str) -> str:\n",
        "    stem = Path(csv_path).stem\n",
        "    return stem.replace(\"_\", \" \").replace(\"-\", \" \").title()\n",
        "\n",
        "def summarise_product(csv_path: str,\n",
        "                      weight_pos: float = 1.0,\n",
        "                      weight_neg: float = -1.0) -> dict:\n",
        "    df = predict_dataframe(pd.read_csv(csv_path))\n",
        "    cnt = df[\"pred_label\"].value_counts().to_dict()\n",
        "    total = len(df)\n",
        "    pos, neu, neg = cnt.get(2, 0), cnt.get(1, 0), cnt.get(0, 0)\n",
        "    score = (weight_pos * pos + weight_neg * neg) / total\n",
        "\n",
        "    # ---> NEW: look up the nice product name\n",
        "    product_name = CSV2NAME.get(str(csv_path), _nice_name_from_filename(csv_path))\n",
        "\n",
        "    return {\n",
        "        \"product_file\": os.path.basename(csv_path),\n",
        "        \"product_name\": product_name,     # ← so Gemini can read it\n",
        "        \"num_reviews\": total,\n",
        "        \"positive\": pos,\n",
        "        \"neutral\": neu,\n",
        "        \"negative\": neg,\n",
        "        \"score\": round(score, 4)\n",
        "    }"
      ],
      "metadata": {
        "id": "kIY_WQVLm0Xy"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _coerce_to_list(csv_input) -> list[str]:\n",
        "    \"\"\"\n",
        "    Accepts:  • real list  -> returns it\n",
        "              • string like '[a.csv, b.csv]' or 'a.csv, b.csv'\n",
        "    Returns:  list[str]\n",
        "    \"\"\"\n",
        "    if isinstance(csv_input, list):\n",
        "        return csv_input\n",
        "\n",
        "    if isinstance(csv_input, str):\n",
        "        txt = csv_input.strip()\n",
        "        # strip surrounding brackets if present\n",
        "        if txt.startswith(\"[\") and txt.endswith(\"]\"):\n",
        "            txt = txt[1:-1]\n",
        "        return [p.strip().strip(\"'\").strip('\"') for p in txt.split(\",\") if p.strip()]\n",
        "\n",
        "    raise TypeError(\"csv_input must be list or str\")\n",
        "\n",
        "\n",
        "def rank_products(csv_input) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Tool entry-point. Works with either real list or comma/bracket string.\n",
        "    \"\"\"\n",
        "    csv_list = _coerce_to_list(csv_input)\n",
        "    summaries = [summarise_product(p) for p in csv_list]\n",
        "    return sorted(summaries, key=lambda d: d[\"score\"], reverse=True)"
      ],
      "metadata": {
        "id": "V7CC8smHm0ee"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class CSVListInput(BaseModel):\n",
        "    csv_files: list[str]"
      ],
      "metadata": {
        "id": "FvRIHR2kQ7DT"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "wraping the two Python functions as langchain tools"
      ],
      "metadata": {
        "id": "827uXGt_m0mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "\n",
        "sentiment_tool = Tool(\n",
        "    name=\"product_sentiment_summary\",\n",
        "    func=summarise_product,\n",
        "    description=(\n",
        "        \"Input: path to ONE product CSV. \"\n",
        "        \"Output: JSON with counts of positive/neutral/negative reviews plus a sentiment score.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "ranking_tool = Tool(\n",
        "    name        = \"rank_multiple_products\",\n",
        "    func        = rank_products,\n",
        "    description = \"Input: list of CSV file paths. Output: same list ordered by score.\",\n",
        "    args_schema = CSVListInput           #  ← NEW\n",
        ")\n",
        "\n",
        "review_tool = Tool(\n",
        "    name        = \"get_review_snippets\",\n",
        "    func        = rag_snippets,\n",
        "    description = (\"Input: product_name. \"\n",
        "                   \"Output: 3-5 quoted review sentences for that product.\")\n",
        ")"
      ],
      "metadata": {
        "id": "M5rRUpO0nJCq"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0.5,\n",
        "    convert_system_message_to_human=True\n",
        ")\n",
        "\n",
        "SYSTEM_MSG = system_prompt_3\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", SYSTEM_MSG),\n",
        "     (\"placeholder\", \"{chat_history}\"),\n",
        "     (\"human\", \"{input}\"),\n",
        "     (\"placeholder\", \"{agent_scratchpad}\")]\n",
        ")\n",
        "\n",
        "tools = [sentiment_tool, ranking_tool, review_tool]\n",
        "\n",
        "agent = create_tool_calling_agent(\n",
        "            llm    = llm,\n",
        "            prompt = prompt,\n",
        "            tools  = tools\n",
        ")\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "gXH5APbXnUkh"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_DIR = Path(\"/content/json2csv_out\")\n",
        "\n",
        "def get_csv_files(directory: Path = CSV_DIR) -> list[str]:\n",
        "    \"\"\"\n",
        "    Walk the folder tree, return **absolute** paths of all .csv files.\n",
        "    \"\"\"\n",
        "    if not directory.exists():\n",
        "        raise FileNotFoundError(f\"CSV directory '{directory}' not found.\")\n",
        "\n",
        "    csv_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for f in files:\n",
        "            if f.lower().endswith(\".csv\"):\n",
        "                csv_paths.append(str(Path(root) / f))\n",
        "\n",
        "    return csv_paths"
      ],
      "metadata": {
        "id": "0j69ZHDwpQdg"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREREQUISITE FOR GEMINI MODE 3 (RANKER) AGENT"
      ],
      "metadata": {
        "id": "Zu5w44D64mih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from langchain.schema import AIMessage\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "def _extract_text(resp) -> str:\n",
        "    \"\"\"\n",
        "    Accepts whatever comes back from agent_executor.invoke()\n",
        "    and returns a printable string.\n",
        "    \"\"\"\n",
        "    out = resp.get(\"output\")\n",
        "\n",
        "    # case 1: plain string\n",
        "    if isinstance(out, str):\n",
        "        return out.strip()\n",
        "\n",
        "    # case 2: AIMessage\n",
        "    if hasattr(out, \"content\"):\n",
        "        return out.content.strip()\n",
        "\n",
        "    # case 3: list of dicts / messages\n",
        "    if isinstance(out, list):\n",
        "        for item in out:\n",
        "            if isinstance(item, dict) and \"text\" in item:\n",
        "                return item[\"text\"].strip()\n",
        "            if hasattr(item, \"content\"):\n",
        "                return item.content.strip()\n",
        "\n",
        "    # fallback\n",
        "    return str(out).strip()"
      ],
      "metadata": {
        "id": "jdiurYQ44wD6"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#THE THREE MODES IN GEMINI"
      ],
      "metadata": {
        "id": "zt_uBpH4RZf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1ST IS BASIC INFORMATION PROVIDER, WHEN IT HAS, INFORMATION ABOUT ONLY ONE PRODUCT\n",
        "\n",
        "def basic_information_provider():\n",
        "    docs = load_documents(rag_dataset_path)\n",
        "    index, _ = index_with_nomic(docs)\n",
        "    return run_rag(index, docs, system_prompt_1)"
      ],
      "metadata": {
        "id": "DGdoizKYRZaW"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2ND IS PRODUCT COMPARISON EXPERT\n",
        "\n",
        "def comparison_master():\n",
        "    docs = load_documents(rag_dataset_path)\n",
        "    index, _ = index_with_nomic(docs)\n",
        "    return run_rag(index, docs, system_prompt_2)"
      ],
      "metadata": {
        "id": "mw3oyiQCRZUW"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unbiased_ranker() -> str:\n",
        "    \"\"\"\n",
        "    • Collect every CSV in /content/json2csv_out\n",
        "    • Ask Gemini (via the agent) to rank & explain\n",
        "    • Return the final markdown (optionally save it to disk)\n",
        "    \"\"\"\n",
        "    csv_paths = get_csv_files()\n",
        "    if len(csv_paths) < 3:\n",
        "        raise ValueError(\"unbiased_ranker() needs at least 3 CSV files\")\n",
        "\n",
        "    human_msg = f\"\"\"\n",
        "    You are an **unbiased product-ranking AI**.\n",
        "\n",
        "    Here is a Python list that contains every CSV review file:\n",
        "    {csv_paths}\n",
        "\n",
        "    Follow these steps STRICTLY:\n",
        "\n",
        "    1. Call `rank_multiple_products` exactly once with\n",
        "      {{\"csv_files\": {csv_paths}}}\n",
        "      (note: that is a JSON object with one key `csv_files`\n",
        "      whose value is the list you see above).\n",
        "\n",
        "    2. The tool will return the products ordered by sentiment score.\n",
        "      For every product in that list, call `get_review_snippets`\n",
        "      using its `product_name` to collect supporting evidence.\n",
        "\n",
        "    3. When you have the evidence, produce:\n",
        "      • an ordered Markdown list (product_name & score)\n",
        "      • a short explanation that *quotes* the snippets you retrieved.\n",
        "\n",
        "    Use ONLY information returned by the tools. Do **not** invent data.\n",
        "\n",
        "    4. For the final answer include:\n",
        "      • an ordered Markdown list (product_name & score)\n",
        "      • underneath each product put the quoted review sentences you obtained\n",
        "        from `get_review_snippets` (keep them inside triple back-ticks).\n",
        "    \"\"\"\n",
        "\n",
        "    resp = agent_executor.invoke({\"input\": human_msg})\n",
        "\n",
        "    final_text = _extract_text(resp)\n",
        "\n",
        "    SAVE_TO_DISK = False\n",
        "    if SAVE_TO_DISK:\n",
        "        ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        file_path = f\"/content/product_ranking_{ts}.txt\"\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(final_text)\n",
        "        print(f\"✓ ranking saved to {file_path}\")\n",
        "\n",
        "    return final_text"
      ],
      "metadata": {
        "id": "FvrdhLbZtC8V"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# running the pipline now"
      ],
      "metadata": {
        "id": "zTh106ONSL-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def auto_run_rag():\n",
        "    \"\"\"\n",
        "    Orchestrates the three modes automatically:\n",
        "\n",
        "      • 1 PDF  → basic_information_provider()\n",
        "      • 2 PDFs → comparison_master()\n",
        "      • ≥3 PDFs → unbiased_ranker()  ← now uses the Gemini agent + tools\n",
        "    \"\"\"\n",
        "    pdf_count = len([f for f in os.listdir(rag_dataset_path) if f.lower().endswith(\".pdf\")])\n",
        "    print(f\"Total PDFs detected: {pdf_count}\")\n",
        "\n",
        "    if pdf_count == 1:\n",
        "        return basic_information_provider()\n",
        "    elif pdf_count == 2:\n",
        "        return comparison_master()\n",
        "    elif pdf_count > 2:\n",
        "        return unbiased_ranker()\n",
        "    else:\n",
        "        print(\"No PDFs found.\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "5k0J4hV-SnUS"
      },
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(auto_run_rag()))  # nice formatting inside a notebook"
      ],
      "metadata": {
        "id": "n7zKYjJ2SzWp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4e53e0b7-2410-46c0-82c4-adade8de47ee"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total PDFs detected: 3\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `rank_multiple_products` with `{'csv_files': ['/content/json2csv_out/product_1_search.csv', '/content/json2csv_out/product_3_search.csv', '/content/json2csv_out/product_2_search.csv']}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m[{'product_file': 'product_3_search.csv', 'product_name': 'Garmin vívoactive 5 Fitness-Tracking Smartwatch with Aluminum Bezel and Silicone Band, Ivory', 'num_reviews': 12, 'positive': 10, 'neutral': 0, 'negative': 2, 'score': 0.6667}, {'product_file': 'product_2_search.csv', 'product_name': 'Apple Watch Series 10 GPS 46mm Jet Black Aluminum Case with Black Sport Band - M/L', 'num_reviews': 12, 'positive': 8, 'neutral': 0, 'negative': 4, 'score': 0.3333}, {'product_file': 'product_1_search.csv', 'product_name': 'SAMSUNG Galaxy Watch 7 SM-L310N (44mm) Wi-Fi Version, AI-ready, Bluetooth Wellness Tips, Heart Rate Tracking, Sleep Monitor, Fitness Tracker, Latin Specs (Green, 44 mm)', 'num_reviews': 12, 'positive': 5, 'neutral': 4, 'negative': 3, 'score': 0.1667}]\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_review_snippets` with `Garmin vívoactive 5 Fitness-Tracking Smartwatch with Aluminum Bezel and Silicone Band, Ivory`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3m```\n",
            "No customer sentences about the Garmin vívoactive 5 Fitness-Tracking Smartwatch are provided in the text.  The provided text only gives summaries of reviews, not verbatim quotes from customers.\n",
            "```\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_review_snippets` with `Apple Watch Series 10 GPS 46mm Jet Black Aluminum Case with Black Sport Band - M/L`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3m```\n",
            "The provided text does not contain verbatim customer sentences about the Apple Watch Series 10 GPS 46mm Jet Black Aluminum Case with Black Sport Band - M/L.  It only summarizes positive and negative reviews.\n",
            "```\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_review_snippets` with `SAMSUNG Galaxy Watch 7 SM-L310N (44mm) Wi-Fi Version, AI-ready, Bluetooth Wellness Tips, Heart Rate Tracking, Sleep Monitor, Fitness Tracker, Latin Specs (Green, 44 mm)`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3m```\n",
            "\"Great watch at an awesome price (Latin version).\"\n",
            "\"Works well with US phones despite being the Latin American version.\"\n",
            "\"Easy setup, but updates may take time.\"\n",
            "\"Some packaging issues reported (torn box), but product arrived intact.\"\n",
            "\"Watch is the Latin American version, not the US version.\"\n",
            "```\u001b[0m\u001b[32;1m\u001b[1;3m# Product Ranking Based on Customer Reviews\n",
            "\n",
            "Here's a ranking of the products based solely on the provided review data, ordered from best to worst:\n",
            "\n",
            "\n",
            "1. **Garmin vívoactive 5 Fitness-Tracking Smartwatch with Aluminum Bezel and Silicone Band, Ivory (Score: 0.6667)**\n",
            "\n",
            "```\n",
            "No customer sentences about the Garmin vívoactive 5 Fitness-Tracking Smartwatch are provided in the text.  The provided text only gives summaries of reviews, not verbatim quotes from customers.\n",
            "```\n",
            "\n",
            "2. **Apple Watch Series 10 GPS 46mm Jet Black Aluminum Case with Black Sport Band - M/L (Score: 0.3333)**\n",
            "\n",
            "```\n",
            "The provided text does not contain verbatim customer sentences about the Apple Watch Series 10 GPS 46mm Jet Black Aluminum Case with Black Sport Band - M/L.  It only summarizes positive and negative reviews.\n",
            "```\n",
            "\n",
            "3. **SAMSUNG Galaxy Watch 7 SM-L310N (44mm) Wi-Fi Version, AI-ready, Bluetooth Wellness Tips, Heart Rate Tracking, Sleep Monitor, Fitness Tracker, Latin Specs (Green, 44 mm) (Score: 0.1667)**\n",
            "\n",
            "```\n",
            "\"Great watch at an awesome price (Latin version).\"\n",
            "\"Works well with US phones despite being the Latin American version.\"\n",
            "\"Easy setup, but updates may take time.\"\n",
            "\"Some packaging issues reported (torn box), but product arrived intact.\"\n",
            "\"Watch is the Latin American version, not the US version.\"\n",
            "```\n",
            "\n",
            "**Reasoning:**\n",
            "\n",
            "The ranking is determined directly by the sentiment scores returned by the `rank_multiple_products` tool.  The supporting review snippets, however, are limited because the available tool only provides summaries and not direct customer quotes for all products.  Therefore, the analysis relies heavily on the numerical scores provided by the tool.  More detailed review text would allow for a more nuanced and comprehensive ranking.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Product Ranking Based on Customer Reviews\n\nHere's a ranking of the products based solely on the provided review data, ordered from best to worst:\n\n\n1. **Garmin vívoactive 5 Fitness-Tracking Smartwatch with Aluminum Bezel and Silicone Band, Ivory (Score: 0.6667)**\n\n```\nNo customer sentences about the Garmin vívoactive 5 Fitness-Tracking Smartwatch are provided in the text.  The provided text only gives summaries of reviews, not verbatim quotes from customers.\n```\n\n2. **Apple Watch Series 10 GPS 46mm Jet Black Aluminum Case with Black Sport Band - M/L (Score: 0.3333)**\n\n```\nThe provided text does not contain verbatim customer sentences about the Apple Watch Series 10 GPS 46mm Jet Black Aluminum Case with Black Sport Band - M/L.  It only summarizes positive and negative reviews.\n```\n\n3. **SAMSUNG Galaxy Watch 7 SM-L310N (44mm) Wi-Fi Version, AI-ready, Bluetooth Wellness Tips, Heart Rate Tracking, Sleep Monitor, Fitness Tracker, Latin Specs (Green, 44 mm) (Score: 0.1667)**\n\n```\n\"Great watch at an awesome price (Latin version).\"\n\"Works well with US phones despite being the Latin American version.\"\n\"Easy setup, but updates may take time.\"\n\"Some packaging issues reported (torn box), but product arrived intact.\"\n\"Watch is the Latin American version, not the US version.\"\n```\n\n**Reasoning:**\n\nThe ranking is determined directly by the sentiment scores returned by the `rank_multiple_products` tool.  The supporting review snippets, however, are limited because the available tool only provides summaries and not direct customer quotes for all products.  Therefore, the analysis relies heavily on the numerical scores provided by the tool.  More detailed review text would allow for a more nuanced and comprehensive ranking."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3zA0eYqJ7K7U"
      },
      "execution_count": 245,
      "outputs": []
    }
  ]
}